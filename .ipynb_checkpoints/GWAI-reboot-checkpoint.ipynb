{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3cbc92-60ed-4694-90e6-5dcca91f0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.special\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bd6c461e-6507-4071-9794-7d8c6fe50c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1mass = torch.tensor([5.0,6.0])\n",
    "c1coup = torch.tensor([1.0,2.0])\n",
    "c1cheby = torch.tensor([3.0,4.0])\n",
    "c2mass = torch.tensor([2.0,2.2])\n",
    "c2coup = torch.tensor([2.0,1.0])\n",
    "c2cheby = torch.tensor([2.0,3.0])\n",
    "chebys = torch.stack([c1cheby,c2cheby])\n",
    "coups = torch.stack([c1coup,c2coup])\n",
    "masses = torch.stack([c1mass,c2mass])\n",
    "s0 = 1.0\n",
    "smin = 0\n",
    "smax = 10\n",
    "kParams = torch.stack([torch.eye(2) for _ in range(2)], dim=0)\n",
    "rmasses = torch.tensor([1.0,1.0])\n",
    "stest = torch.view_as_complex(torch.Tensor([5,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7b1ffa2a-2c4c-4cc1-b26f-24efa299ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(s: torch.Tensor, masses: torch.Tensor):\n",
    "    return 0.5*torch.sqrt(s-masses.sum()**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0a8c247d-440f-4657-8b84-5d290b505ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0232+5.3852j)\n",
      "tensor(0.0703+1.7790j)\n"
     ]
    }
   ],
   "source": [
    "print(momentum(stest,c1mass))\n",
    "print(momentum(stest,c2mass))\n",
    "#works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "41f9e614-4f87-4c24-bf8b-7fbab1245ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s should be a torch tensor containing all values of s at which we're evaluating. \n",
    "#Returns a tensor of the same shape as the input\n",
    "def omega_pole(s,s0):\n",
    "    return s/(s+s0)\n",
    "def omega_scaled(s,smin,smax):\n",
    "    return -torch.ones(s.shape)+2*(s-smin)/(smax-smin)\n",
    "def omega_pole_scaled(s, s0, smin, smax):\n",
    "    return torch.ones(s.shape)+2*(omega_pole(s,s0)-omega_pole(smin,s0))/(omega_pole(smin,s0)-omega_pole(smax,s0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b17f41c7-92de-4a0e-8111-a6d904add72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebyshev_t(n, s):\n",
    "    # s must be in [-1,1] for a real result.\n",
    "    return torch.cos(n * torch.acos(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4af77f82-3b04-40d6-acd9-c9a307da9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerator(s:torch.Tensor, coeff:torch.Tensor)->torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes S_m(s) = sum_{n=0}^{N-1} coeff[m, n] * T_n(s) for each set m.\n",
    "\n",
    "    Parameters:\n",
    "        coeff (Tensor): A 2D tensor of shape (M, N) where each row m contains coefficients.\n",
    "        s (Tensor): A tensor of evaluation points (can be any shape).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: A tensor of shape (M, *s.shape) where each row m is the series evaluated at s.\n",
    "    \"\"\"\n",
    "    M, N = coeff.shape\n",
    "    degrees = torch.arange(N, device=coeff.device)\n",
    "    Tns = torch.stack([chebyshev_t(n, s) for n in degrees], dim=0)\n",
    "    \n",
    "    # Reshape coeff to (M, N, 1, ..., 1) so it can broadcast with Tns.\n",
    "    # s.ndim gives the number of dimensions in s.\n",
    "    coeff_reshaped = coeff.view(M, N, *([1] * s.ndim))\n",
    "    \n",
    "    # Multiply the coefficients with the corresponding T_n(s) and sum over n (the Chebyshev index).\n",
    "    result = (coeff_reshaped * Tns.unsqueeze(0)).sum(dim=1)\n",
    "    return result\n",
    "    #works!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "daeeae82-562d-4807-9b13-95338dccb97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 6.5556],\n",
       "        [3.5000, 4.6667]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator(torch.tensor([0.5,0.8889]),chebys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4effee-707c-4423-8159-64d2e494c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhoNnominal(sprime: torch.Tensor, p: torch.Tensor, J: int, alpha: float, sL: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes a batch of diagonal matrices for the nominal rhoN function.\n",
    "    \n",
    "    For each scalar s' in sprime, it returns a vector of length num_p whose entries are:\n",
    "    \n",
    "        (2 * p[j])^(2*J+1) / (s' + sL)^(2*J+alpha)\n",
    "    \n",
    "    Parameters:\n",
    "      sprime : torch.Tensor of shape (N,), the energy squared values (s').\n",
    "      p    : torch.Tensor of shape (P,), one-dimensional tensor with one momentum value per channel.\n",
    "      J      : Scalar, the angular momentum.\n",
    "      alpha  : Scalar.\n",
    "      sL     : Scalar.\n",
    "    \n",
    "    Returns:\n",
    "      A torch.Tensor of shape (N, P, P) where for each i, result[i] is a diagonal matrix with\n",
    "      diag[j] = (2 * p_i[j])^(2*J+1) / (sprime[i] + sL)^(2*J+alpha)\n",
    "    \"\"\"\n",
    "    # Compute numerator: (2 * p_i)^(2J+1) for each channel\n",
    "    num = (2 * p) ** (2 * J + 1)  # shape: (P,)\n",
    "    # Compute denominator for each s' value: (s' + sL)^(2J+alpha)\n",
    "    # Unsqueeze sprime to shape (N, 1) so broadcasting works.\n",
    "    denom = (sprime.unsqueeze(1) + sL) ** (2 * J + alpha)  # shape: (N, 1)\n",
    "    # Calculate diagonal values for each s'\n",
    "    return num / denom  # shape: (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c796918-52d7-4225-ac63-aebd678c1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = torch.tensor([6.2])\n",
    "ps = torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4065cbe-019e-4751-bdec-606624b84573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def K_nominal(s: torch.Tensor, m_r: torch.Tensor, couplings: torch.Tensor, C: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the nominal K-matrix as a function of s.\n",
    "    \n",
    "    For n_ch channels and R resonances, the K-matrix is given by:\n",
    "    \n",
    "        K_{k,i}(s) = (sum_{r=1}^R g_{r,k} * g_{r,i} / (m_r[r]^2 - s)) + \n",
    "                      (C[0] + C[1]*s + C[2]*s^2 + ...)\n",
    "\n",
    "    Parameters:\n",
    "      s         : 1D torch.Tensor of shape (num_pts,) containing s values.\n",
    "      m_r       : 1D torch.Tensor of shape (R,) containing resonance masses.\n",
    "      couplings : torch.Tensor of shape (R, n_ch) with coupling constants g_{r,k}.\n",
    "      C         : torch.Tensor of shape (n_poly, n_ch, n_ch) containing polynomial background terms.\n",
    "\n",
    "    Returns:\n",
    "      A torch.Tensor of shape (num_pts, n_ch, n_ch) where each slice along the first dimension\n",
    "      is the computed K-matrix at that s value.\n",
    "    \"\"\"\n",
    "    # Ensure s is a float tensor (and m_r, couplings, C are proper type)\n",
    "    s = s.to(torch.float64)\n",
    "    m_r = m_r.to(torch.float64)\n",
    "    couplings = couplings.to(torch.float64)\n",
    "    C = C.to(torch.float64)\n",
    "    \n",
    "    num_pts = s.shape[0]\n",
    "    R, n_ch = couplings.shape\n",
    "\n",
    "    # Compute the resonance contribution:\n",
    "    # For each resonance r, compute g_{r,k} * g_{r,i} as an outer product.\n",
    "    # This yields a tensor of shape (R, n_ch, n_ch).\n",
    "    G = torch.einsum('rk,ri->rki', couplings, couplings)  # shape: (R, n_ch, n_ch)\n",
    "\n",
    "    # Compute denominator for each resonance r and each s:\n",
    "    # m_r^2 - s. Here m_r is shape (R,) and s is shape (num_pts,).\n",
    "    # We compute m_r^2 as a tensor of shape (R,)\n",
    "    m_r_sq = m_r ** 2  # shape (R,)\n",
    "    # Expand s and m_r_sq to combine: shape becomes (num_pts, R)\n",
    "    denom = m_r_sq.view(1, R) - s.view(num_pts, 1)  # shape: (num_pts, R)\n",
    "    \n",
    "    # Reshape denominator for broadcasting: (num_pts, R, 1, 1)\n",
    "    denom_exp = denom.unsqueeze(2).unsqueeze(3)\n",
    "    # Expand G to shape (1, R, n_ch, n_ch) so it broadcasts over s.\n",
    "    G_exp = G.unsqueeze(0)  # shape: (1, R, n_ch, n_ch)\n",
    "    # Compute resonance part: for each s value, sum over resonances:\n",
    "    resonance_term = torch.sum(G_exp / denom_exp, dim=1)  # shape: (num_pts, n_ch, n_ch)\n",
    "    \n",
    "    # Compute the polynomial (background) part:\n",
    "    n_poly = C.shape[0]\n",
    "    # Compute powers of s: a tensor of shape (num_pts, n_poly) where element (i, j) = s[i]^j.\n",
    "    s_powers = torch.stack([s**j for j in range(n_poly)], dim=1)  # shape: (num_pts, n_poly)\n",
    "    # Reshape to (num_pts, n_poly, 1, 1) for broadcasting\n",
    "    s_powers = s_powers.unsqueeze(2).unsqueeze(3)\n",
    "    # Expand C to (1, n_poly, n_ch, n_ch)\n",
    "    C_exp = C.unsqueeze(0)\n",
    "    # Multiply and sum over the polynomial order dimension:\n",
    "    poly_term = torch.sum(s_powers * C_exp, dim=1)  # shape: (num_pts, n_ch, n_ch)\n",
    "    \n",
    "    # Final K matrix is the sum of resonance and polynomial terms:\n",
    "    K_total = resonance_term + poly_term\n",
    "    return K_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e686a867-ab53-47c3-9605-d3cbf59c6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def compute_s_over_pi_I(s: torch.Tensor,\n",
    "                        rhoNnominal_fn,\n",
    "                        s_th: torch.Tensor,\n",
    "                        p: torch.Tensor,\n",
    "                        J: int,\n",
    "                        alpha: float,\n",
    "                        sL: float,\n",
    "                        epsilon: float,\n",
    "                        upper_bound: float = 1e6) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes (s/π) * I(s), where\n",
    "    \n",
    "        I_{ki}(s) = ∫_{s_th[k]}^∞  [ρNnominal_{ki}(s') / (s' * (s' - s - iε))] ds'.\n",
    "    \n",
    "    Parameters:\n",
    "      s                : 1D torch.Tensor of shape (num_pts,) with energy-squared values.\n",
    "      rhoNnominal_fn   : Function with signature \n",
    "                         rhoNnominal_fn(sprime, p, J, alpha, sL) \n",
    "                         that returns a tensor of shape (n_sp, n_ch, n_ch).\n",
    "      s_th             : 1D torch.Tensor of shape (n_ch,) with threshold values (s_th for each channel).\n",
    "      p                : 1D torch.Tensor of shape (n_ch,) with momentum values for each channel.\n",
    "      J                : Integer angular momentum.\n",
    "      alpha            : Float parameter.\n",
    "      sL               : Float parameter (used inside rhoNnominal_fn).\n",
    "      epsilon          : Small positive float for the iε prescription.\n",
    "      upper_bound      : Upper integration limit (default 1e6) to approximate ∞.\n",
    "      \n",
    "    Returns:\n",
    "      A torch.Tensor of shape (num_pts, n_ch, n_ch) representing (s/π)*I(s).\n",
    "    \"\"\"\n",
    "    # Ensure s is complex for proper handling of i*epsilon.\n",
    "    s = s.to(torch.cfloat)   # shape: (num_pts,)\n",
    "    s_th = s_th.to(s.dtype)    # shape: (n_ch,)\n",
    "    p = p.to(s.dtype)          # shape: (n_ch,)\n",
    "    \n",
    "    num_pts = s.shape[0]\n",
    "    n_ch = s_th.shape[0]\n",
    "    \n",
    "    # Set integration grid for s': from the smallest threshold to upper_bound.\n",
    "    sprime_min = float(torch.min(s_th).real)  # minimum threshold over all channels\n",
    "    sprime_max = upper_bound                   # fixed high value to approximate ∞\n",
    "    N_integ = 1000                           # number of integration points; adjust for accuracy\n",
    "    sprime = torch.linspace(sprime_min, sprime_max, steps=N_integ, dtype=torch.float64)\n",
    "    \n",
    "    # Compute rhoNnominal(s') for all integration points.\n",
    "    # Expected shape: (N_integ, n_ch, n_ch)\n",
    "    rho_vals = rhoNnominal_fn(sprime, p, J, alpha, sL)\n",
    "    rho_vals = rho_vals.to(torch.cfloat)\n",
    "    \n",
    "    # Divide rho by s'\n",
    "    sprime_expanded = sprime.view(-1, 1, 1)  # shape: (N_integ, 1, 1)\n",
    "    integrand = rho_vals / sprime_expanded   # shape: (N_integ, n_ch, n_ch)\n",
    "    \n",
    "    sprime_complex = sprime.to(torch.cfloat)  # shape: (N_integ,)\n",
    "    s_complex = s  # already complex, shape: (num_pts,)\n",
    "    denom = sprime_complex.view(-1, 1) - s_complex.view(1, -1) - 1j * epsilon  # shape: (N_integ, num_pts)\n",
    "    factor = 1.0 / denom   # shape: (N_integ, num_pts), complex\n",
    "    \n",
    "    # Expand integrand: currently (N_integ, n_ch, n_ch).\n",
    "    # Expand factor to (N_integ, num_pts, 1, 1) so it multiplies each matrix element.\n",
    "    factor_expanded = factor.unsqueeze(-1).unsqueeze(-1)  # shape: (N_integ, num_pts, 1, 1)\n",
    "    integrand = integrand.unsqueeze(1)  # shape: (N_integ, 1, n_ch, n_ch)\n",
    "    full_integrand = integrand * factor_expanded   # shape: (N_integ, num_pts, n_ch, n_ch)\n",
    "    \n",
    "    # Apply threshold masking: for each channel k, we want s' < s_th[k] to yield zero contribution.\n",
    "    # Create mask: shape (N_integ, n_ch) where each element is 1 if sprime >= s_th[k] else 0.\n",
    "    mask = (sprime.view(-1, 1) >= s_th.view(1, -1)).to(torch.cfloat)  # shape: (N_integ, n_ch)\n",
    "    # Expand mask to (N_integ, 1, n_ch, 1) so that it zeroes out the entire row for channel k.\n",
    "    mask_expanded = mask.unsqueeze(1).unsqueeze(-1)  # shape: (N_integ, 1, n_ch, 1)\n",
    "    \n",
    "    full_integrand = full_integrand * mask_expanded\n",
    "    \n",
    "    # Numerically integrate over s' using the trapezoidal rule along dimension 0.\n",
    "    # The integration variable is sprime.\n",
    "    I_s = torch.trapz(full_integrand, sprime, dim=0)  # shape: (num_pts, n_ch, n_ch)\n",
    "    \n",
    "    # Multiply by s/pi:\n",
    "    s_over_pi = (s / math.pi).view(-1, 1, 1)  # shape: (num_pts, 1, 1)\n",
    "    result = s_over_pi * I_s  # shape: (num_pts, n_ch, n_ch)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f2a15-08ed-4c81-a5f6-37e0d17b8d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
